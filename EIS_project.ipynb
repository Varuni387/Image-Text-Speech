{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varuni387/Image-Text-Speech/blob/main/EIS_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWSWOQbnQR2w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0siZo1IGUFqX"
      },
      "outputs": [],
      "source": [
        "images=[]\n",
        "for i in range(1, 2):  # Assuming you have one image for this example\n",
        "    image_path = \"/content/Capture_\" + str(i) + \".jpg\"  # Ensure the filename and path are correct\n",
        "    print(f\"Reading image from: {image_path}\")  # Checking if path is correct\n",
        "    capture = cv2.imread(image_path)\n",
        "\n",
        "    if capture is not None:\n",
        "        print(f\"Image {i} read successfully\")\n",
        "        images.append(capture)\n",
        "    else:\n",
        "        print(f\"Failed to read image {i}\")\n",
        "\n",
        "# Check if there are any images in the list before displaying\n",
        "if len(images) > 0:\n",
        "    # Code to display 1 image\n",
        "    print(\"Displaying the first image\")\n",
        "    plt.imshow(cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')  # Hide axis for better display\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thgv3s6TWTYg"
      },
      "outputs": [],
      "source": [
        "!pip install tesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr"
      ],
      "metadata": {
        "id": "HmJn9hY7ILNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3PpEAyFWpg3"
      },
      "outputs": [],
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfE04W-cXIO-"
      },
      "outputs": [],
      "source": [
        "!tesseract -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14ZUyy4sW4Ah"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiOp14iXW7BQ"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract\n",
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = (r'/bin/tesseract')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpAqcp6qXm3l"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"/content/Capture_1.jpg\")\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "example_text=pytesseract.image_to_string(img)\n",
        "print(pytesseract.image_to_string(img))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "graAYqt7CPZx"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchaudio omegaconf\n",
        "\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from omegaconf import OmegaConf\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
        "                               'latest_silero_models.yml',\n",
        "                               progress=False)\n",
        "models = OmegaConf.load('latest_silero_models.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gqwRZ4LHRGr"
      },
      "outputs": [],
      "source": [
        "available_languages = list(models.tts_models.keys())\n",
        "print(f'Available languages {available_languages}')\n",
        "for lang in available_languages:\n",
        "    _models = list(models.tts_models.get(lang).keys())\n",
        "    print(f'Available models for {lang}: {_models}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QMN0Em-HWJ5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "language = 'en'\n",
        "model_id = 'v3_en'\n",
        "device = torch.device('cpu')\n",
        "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                     model='silero_tts',\n",
        "                                     language=language,\n",
        "                                     speaker=model_id)\n",
        "model.to(device)  # gpu or cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4Mg-13cDi2s"
      },
      "outputs": [],
      "source": [
        "model.speakers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zomn-l6VOrwq"
      },
      "outputs": [],
      "source": [
        "sample_rate = 48000\n",
        "speaker = 'en_1'\n",
        "put_accent=True\n",
        "put_yo=True\n",
        "#example_text = 'Can specify of your own to check'\n",
        "\n",
        "audio = model.apply_tts(text=example_text,\n",
        "                        speaker=speaker,\n",
        "                        sample_rate=sample_rate,\n",
        "                        put_accent=put_accent,\n",
        "                        put_yo=put_yo)\n",
        "print(example_text)\n",
        "display(Audio(audio, rate=sample_rate))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(audio, 'generated_audio.pt')"
      ],
      "metadata": {
        "id": "Z7NbMeT35Km2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKxKoAZ-OuHI"
      },
      "outputs": [],
      "source": [
        "ssml_sample = \"\"\"\n",
        "              <speak>\n",
        "              <p>\n",
        "                  I am currently working on <prosody rate=\"x-slow\">Embedded course</prosody>.\n",
        "                  project <prosody pitch=\"x-high\"> The title of the project is </prosody>,\n",
        "                  <prosody pitch=\"x-low\">Converting image to text to speech </prosody>.\n",
        "                 <prosody rate=\"fast\">Hope so I will be</prosody>\n",
        "                  able to finish it soon<break time=\"2000ms\"/>.\n",
        "              </p>\n",
        "              </speak>\n",
        "              \"\"\"\n",
        "\n",
        "sample_rate = 48000\n",
        "speaker = 'en_1'\n",
        "audio = model.apply_tts(ssml_text=ssml_sample,\n",
        "                        speaker=speaker,\n",
        "                        sample_rate=sample_rate)\n",
        "display(Audio(audio, rate=sample_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJvIF2NP2A6"
      },
      "source": [
        "Random speaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L-Yc9sROvyW"
      },
      "outputs": [],
      "source": [
        "sample_rate = 48000\n",
        "speaker = 'random'\n",
        "\n",
        "example_text = 'Trying to generate random voice'\n",
        "\n",
        "audio = model.apply_tts(text=example_text,\n",
        "                        speaker=speaker,\n",
        "                        sample_rate=sample_rate)\n",
        "print(example_text)\n",
        "display(Audio(audio, rate=sample_rate))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/9czp8Jya8zbX9YOD0nL4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}